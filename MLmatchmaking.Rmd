---
title: "Using Machine Learning For Matchmaking"
output: rmarkdown::github_document
editor_options: 
  chunk_output_type: inline
  include: TRUE
---


###Objective:
- Using clustering algorithms to cluster people based on their interests.
- Finding people for a random user from his cluster group.
- Ranking them based on how much their personality matches with the user's personality

###Datasets used:
- Big5 personality dataset
- Interests dataset
- Baby-names dataset
  
###Approach:
1. Combining Big5 personality dataset with personality dataset
2. Adding names for ease in identification
3. Using PCA for dimention reduction in both Big5 and Interests columns
4. Using the PCA'd data to run heirarchical clustering
5. Finding the appropriate no of cluster from heirarchical clustering
6. Clustering the data using K-Means Clustering
7. Attaching cluster assignments to the original PCA'd dataset
8. Selecting a user
9. Filtering out people within same cluster, country, age-group as user's
10. Creating a list of people with personality most similar to user's
  
  

```{r}
library(cluster)
library(dplyr)
setwd('E:/Datasets/BIG5/Data')
```

###Reading the Big5 dataset

```{r}
big = read.csv('data.csv', sep= "")
head(big)
```
(Refer to Readme)

```{r}
str(big)
```

Removing NAs and unwanted columns 

```{r}
big = big[,-c(5,6)]
head(big)
big = na.omit(big)
```
```{r}
names(big)
dim(big)
```

Countries of respondents

```{r}
sort(table(big$country), decreasing = TRUE)
```

Removing rows with vague age values 

```{r}
unique(big$age)
big = big[!(big$age>=120),]
unique(big$age)
```


###Taking a sample of 5000 respondents (due to computational reasons)

```{r}
set.seed(2)
train = big[sample.int(nrow(big), 5000),]
remove(big)
```


Adding 5000 unique names for easier identification

```{r}
names=read.csv('baby-names.csv')
```
```{r}
names = names$name
names = unique(names)
names = names[sample.int(length(names), 5000)]
```
```{r}
train = data.frame(names,train)
train[1:6,1:6]
```


###Reading the interests dataset

```{r}
int = read.csv('interests.csv')
head(int)
int = na.omit(int)
```

```{r}
knitr::opts_chunk$set(echo = FALSE, 
                      warning = FALSE, 
                      messages = FALSE, 
                      include = TRUE)
heatmap(cor(int[,-51]))
```

Creating a dataset of 5000 from 800 with replacement

```{r}
set.seed(2)
intlarge = int[sample.int(nrow(int), 5000, replace = TRUE),]
summary(int)
```


###Master dataset with names, Big5 data and Interest data
```{r}
train = data.frame(train, intlarge)
names(train)
```

```{r}
sort(table(train$Education), decreasing = TRUE)
```
```{r}
knitr::opts_chunk$set(echo = FALSE, 
                      warning = FALSE, 
                      messages = FALSE, 
                      include = TRUE)
hist(train$age, col = 'red', xlab = 'Age', ylab = 'Frequency', main = 'AGE FREQUENCY')
```
```{r}
knitr::opts_chunk$set(echo = FALSE, 
                      warning = FALSE, 
                      messages = FALSE, 
                      include = TRUE)
hist(train$gender, col = 'blue', xlab = 'Gender
     1=Male, 2=Female, 3=Other', ylab = 'Frequency', main = 'GENDER FREQUENCY')
```




#PRINCIPAL COMPONENT ANALYSIS


##Principal Component Analysis on interest columns

```{r}
pr.out = prcomp(intlarge[,1:50], scale = TRUE)
head(pr.out$rotation[1:20])
```
```{r}
knitr::opts_chunk$set(echo = FALSE, 
                      warning = FALSE, 
                      messages = FALSE, 
                      include = TRUE)

head(pr.out$x)
par(mfrow=c(1,1))
plot(pr.out$x[,1:2], pch=19, xlab = 'PC1', ylab='PC2')
plot(pr.out$x[,c(1,3)], pch=19, xlab = 'PC1', ylab='PC3')
```

```{r}
knitr::opts_chunk$set(echo = FALSE, 
                      warning = FALSE, 
                      messages = FALSE, 
                      include = TRUE)

summary(pr.out)
plot(pr.out$sdev, xlab='Principal Component', ylab='Standard Deviation', main='Standard Deviation explained by each PC')
```


Proportion of Variance explained by each additional PC

```{r}
knitr::opts_chunk$set(echo = FALSE, 
                      warning = FALSE, 
                      messages = FALSE, 
                      include = TRUE)

pve = 100*pr.out$sdev^2/sum(pr.out$sdev^2)
par(mfrow=c(1,2))
plot(pve[1:18],type='o',ylab='Prop. var. explained', xlab="Principal Component", col='blue')
plot(cumsum(pve[1:18]),type='o',ylab='Cum. Prop. var. explained', xlab="Principal Component", col='blue')
```


Setting a cutoff point at 60% cumulative percentage

```{r}
knitr::opts_chunk$set(echo = FALSE, 
                      warning = FALSE, 
                      messages = FALSE, 
                      include = TRUE)

par(mfrow=c(1,1))
plot(cumsum(pve[1:18]),type='o',ylab='Cum. Prop. var. explained', xlab="Principal Component", col='blue')
abline(h=60)
```

```{r}
head(pr.out$x[,1:14])
```


###Taking out the first 14 PCs

```{r}
pca.int.data = pr.out$x[,1:14]
head(pca.int.data)
```



##Principal Component Analysis on Big5 columns

```{r}
dim(train)
pr.out2 = prcomp(train[,7:56], scale = TRUE)
head(pr.out2$rotation[,1:20])
```

```{r}
knitr::opts_chunk$set(echo = FALSE, 
                      warning = FALSE, 
                      messages = FALSE, 
                      include = TRUE)

head(pr.out2$x)
par(mfrow=c(1,1))
plot(pr.out2$x[,1:2], pch=19, xlab = 'PC1', ylab='PC2')
plot(pr.out2$x[,c(1,3)], pch=19, xlab = 'PC1', ylab='PC3')
```

```{r}
knitr::opts_chunk$set(echo = FALSE, 
                      warning = FALSE, 
                      messages = FALSE, 
                      include = TRUE)

summary(pr.out2)
plot(pr.out2$sdev, xlab='Principal Component', ylab='Standard Deviation', main='Standard Deviation explained by each PC')
```


Proportion of Variance explained by each additional PC 

```{r}
knitr::opts_chunk$set(echo = FALSE, 
                      warning = FALSE, 
                      messages = FALSE, 
                      include = TRUE)

pve2= 100*pr.out2$sdev^2/sum(pr.out2$sdev^2)
par(mfrow=c(1,2))
plot(pve2[1:20],type='o',ylab='Prop. var. explained', xlab="Principal Component", col='blue')
plot(cumsum(pve2[1:20]),type='o',ylab='Cum. Prop. var. explained', xlab="Principal Component", col='blue')
```


Setting a cutoff point at 60% cumulative percentage

```{r}
knitr::opts_chunk$set(echo = FALSE, 
                      warning = FALSE, 
                      messages = FALSE, 
                      include = TRUE)

par(mfrow=c(1,1))
plot(cumsum(pve2[1:18]),type='o',ylab='Cum. Prop. var. explained', xlab="Principal Component", col='blue')
abline(h=60)
```

```{r}
head(pr.out2$x[,1:12])
```


###Taking out first 12 PCs

```{r}
pca.big.data = pr.out2$x[,1:12]
head(pca.big.data)
```


###Creating a dataframe with Principal Component values only

```{r}
pcatrain = data.frame(train[,1:6], pca.big.data)
names(pcatrain) 
names(pcatrain) = c("names","race","age","engnat","gender","country",
                    "bigPC1","bigPC2","bigPC3","bigPC4","bigPC5","bigPC6","bigPC7","bigPC8","bigPC9","bigPC10","bigPC11","bigPC12")
head(pcatrain)
```
```{r}
pcatrain = data.frame(pcatrain, pca.int.data)
names(pcatrain) 
names(pcatrain) = c("names","race","age","engnat","gender","country",
                    "bigPC1","bigPC2","bigPC3","bigPC4","bigPC5","bigPC6","bigPC7","bigPC8","bigPC9","bigPC10","bigPC11","bigPC12",
                    "intPC1","intPC2","intPC3","intPC4","intPC5","intPC6","intPC7","intPC8","intPC9","intPC10","intPC11","intPC12","intPC13","intPC14")
```

```{r}
head(pcatrain)
names(pcatrain)
```


```{r}
remove(pr.out)
remove(pr.out2)
remove(pca.big.data)
remove(pca.int.data)
```




#CLUSTERING PEOPLE ON THE BASIS OF THEIR INTERESTS


##Heirarchical Clustering

```{r}
head(pcatrain)
scaled = scale(pcatrain[,7:32])
summary(pcatrain[,7:32])
```

```{r}
distances = dist(scaled[,13:26], method = "euclidean")
hc = hclust(distances, method = 'ward.D')
remove(distances)
```

Plotting the dendogram
```{r}
knitr::opts_chunk$set(echo = FALSE, 
                      warning = FALSE, 
                      messages = FALSE, 
                      include = TRUE)

plot(hc)
abline(h=185, col = 'red')
```


###Setting the value of clusters at 12
```{r}
hc.cluster = cutree(hc, h=185)
head(hc.cluster)
remove(scaled)
```



##KMeansClustering

```{r}
knitr::opts_chunk$set(echo = FALSE, 
                      warning = FALSE, 
                      messages = FALSE, 
                      include = TRUE)

kmc = kmeans(pcatrain[,7:32], centers = 12, iter.max = 20)
head(kmc$cluster)
par(mfrow = c(1,1))
plot(kmc$cluster)
```
```{r}
kmc$cluster[1:10]
```


Joining the cluster assigned with the PCA'd data

```{r}
cluster = kmc$cluster
pcatrain = data.frame(pcatrain, cluster)
names(pcatrain)
```



#FINAL STEPS

###Selecting close matches for selected user
```{r}
user = pcatrain[pcatrain$names == 'Penni',]
user
```

###Filtering out people from the same cluster, age-group and country
```{r}
closecluster = pcatrain %>% filter(kmc$cluster == user$cluster)
refined = as.data.frame(subset(closecluster,closecluster$country == user$country & closecluster$gender != user$gender & (closecluster$age >= (user$age-3) & closecluster$age <= (user$age+3))))
head(refined)
```

###Finding people with personality most similar to user's
```{r}
for(i in c(1:nrow(refined))) {refined$sumdifference[i] = sum(sqrt((refined[i,7:18]-user[,7:18])^2))}
selected = head(refined[order(refined$sumdifference),],10)$names
selected
```
```{r}
head(refined[order(refined$sumdifference),c(1,33)],10)
```



##Original responses of the filtered people and user

```{r}
train[train$names==user$names,]
train[train$names %in% selected,]
```

####Thanks for sticking till the end
####You can connect with me on:
####[LinkedIn](https://www.linkedin.com/in/shariq06ahmed/)
####[GitHub](https://github.com/ShariqAhmed007)


